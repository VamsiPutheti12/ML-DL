# ğŸ­ Facial Emotion Recognition with ResNet-18

This project classifies human facial expressions into seven emotions using a deep convolutional neural network. It leverages **transfer learning** with a **pretrained ResNet-18** model and is trained on the **FER2013 dataset**. You can also test the model interactively using a web-based app powered by **Gradio**.

---

## ğŸ“‚ Dataset

- **Name**: [FER2013](https://www.kaggle.com/datasets/deadskull7/fer2013)
- **Classes**:
  - Angry ğŸ˜ 
  - Disgust ğŸ¤¢
  - Fear ğŸ˜¨
  - Happy ğŸ˜„
  - Sad ğŸ˜¢
  - Surprise ğŸ˜²
  - Neutral ğŸ˜
- **Format**: 48x48 grayscale images (converted to folders with PyTorch-compatible structure)

---

## ğŸ§  Model Overview

| Component      | Details                 |
|----------------|--------------------------|
| Base Model     | ResNet-18 (pretrained on ImageNet) |
| Final Layer    | Fully connected â†’ 7 classes |
| Framework      | PyTorch (via Google Colab) |
| Loss Function  | CrossEntropyLoss         |
| Optimizer      | Adam                     |
| Augmentations  | Resize, Crop, Flip       |

---

## ğŸ“ˆ Results

- âœ… **Train accuracy**: ~90%
- âœ… **Validation accuracy**: ~75%
- âœ… **Test accuracy**: ~72%
- ğŸ“‰ Includes loss/accuracy plots + confusion matrix
- ğŸ¨ Prediction visualizations from test images

---

## ğŸš€ How to Run

### ğŸ”§ 1. Train the model (in Colab or locally)
```bash
python fer2013_training.py

